{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from ds_utils.ml import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ds_utils\n",
    "\n",
    "> Data Science Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install ds_utils\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development notes\n",
    "\n",
    "This library has been developed using [nbdev](https://nbdev.fast.ai). Any change or PR has to be made directly to the notebooks that creates each module. All tests must pass.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Before commiting your changes to GitHub we recommend running nbdev_prepare in the terminal, which bundles the following commands:\n",
    "```\n",
    "nbdev_export: Builds the .py modules from Jupyter notebooks\n",
    "nbdev_test: Tests your notebooks\n",
    "nbdev_clean: Cleans your notebooks to get rid of extreanous output for git\n",
    "nbdev_readme: Updates your repoâ€™s README.md file from your index notebook.\n",
    "TODO:\n",
    "- Continue guide available here: https://nbdev.fast.ai/tutorials/tutorial.html#upload-to-pypi\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ml.RegressorCV` Class\n",
    "\n",
    "### Overview\n",
    "The `RegressorCV` class in the `ml.py` module of the `ds_utils` library is designed to train an estimator using cross-validation and record metrics for each fold. It also stores each model that is trained on each fold of the cross-validation process. The final prediction is made as the median value of the predictions from each stored model.\n",
    "\n",
    "### Initialization\n",
    "```python\n",
    "RegressorCV(base_reg, cv=5, groups=None, verbose=False, n_bins_stratify=None)\n",
    "```\n",
    "\n",
    "#### Parameters\n",
    "- `base_reg` : Estimator object implementing 'fit'. The object to use to fit the data.\n",
    "- `cv` : int or cross-validation generator, default=5. Determines the cross-validation splitting strategy.\n",
    "- `groups` : array-like of shape (n_samples,), default=None. Group labels for the samples used while splitting the dataset into train/test set.\n",
    "- `n_bins_stratify` : int, default=None. Number of bins to use for stratification.\n",
    "- `verbose` : bool, default=False. Whether or not to print metrics.\n",
    "\n",
    "### Attributes\n",
    "- `cv_results_` : Dictionary containing the results of the cross-validation, including the fold number, the regressor, and the metrics.\n",
    "- `oof_train_` : Series containing the out-of-fold predictions on the training set.\n",
    "- `oof_score_` : The R2 score calculated using the out-of-fold predictions.\n",
    "- `oof_mape_` : The Mean Absolute Percentage Error calculated using the out-of-fold predictions.\n",
    "- `oof_rmse_` : The Root Mean Squared Error calculated using the out-of-fold predictions.\n",
    "- `metrics_` : The summary of metrics calculated during the fitting process.\n",
    "\n",
    "### Methods\n",
    "\n",
    "#### fit(self, X, y, **kwargs)\n",
    "Trains the base regressor on the provided data using cross-validation and stores the results.\n",
    "\n",
    "#### predict(self, X)\n",
    "Predicts the target variable for the provided features using the median value of the predictions from the models trained during cross-validation.\n",
    "\n",
    "### Example\n",
    "```python\n",
    "from ds_utils.ml import RegressorCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the RegressorCV with a base regressor and cross-validation strategy\n",
    "reg_cv = RegressorCV(base_reg=RandomForestRegressor(), cv=5, verbose=True)\n",
    "\n",
    "# Fit the RegressorCV to the training data\n",
    "reg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for new data\n",
    "predictions = reg_cv.predict(X_new)\n",
    "\n",
    "# Get the summary of recorded metrics\n",
    "metrics = reg_cv.metrics_\n",
    "```\n",
    "\n",
    "## `ml.RegressorTimeSeriesCV` Class\n",
    "\n",
    "### Overview\n",
    "The `RegressorTimeSeriesCV` class in the `ml.py` module of the `ds_utils` library is designed to train a base regressor using time series cross-validation and record metrics for each fold.\n",
    "\n",
    "### Initialization\n",
    "```python\n",
    "RegressorTimeSeriesCV(base_reg, cv=5, verbose=False, catboost_use_eval_set=False)\n",
    "```\n",
    "\n",
    "#### Parameters\n",
    "- `base_reg` : Estimator object implementing 'fit'. The object to use to fit the data.\n",
    "- `cv` : int, default=5. Determines the cross-validation splitting strategy.\n",
    "- `verbose` : bool, default=False. Whether or not to print metrics.\n",
    "- `catboost_use_eval_set` : bool, default=False. Whether or not to use eval_set in CatBoostRegressor.\n",
    "\n",
    "### Attributes\n",
    "- `cv_results_` : List containing the results of the cross-validation, including fold number, regressor, train and test indices, and metrics.\n",
    "- `metrics_` : The summary of metrics calculated during the fitting process.\n",
    "- `y_test_last_fold_` : The true target variable values of the last fold.\n",
    "- `y_pred_last_fold_` : The predicted target variable values of the last fold.\n",
    "\n",
    "### Methods\n",
    "\n",
    "#### fit(self, X, y, sample_weight=None)\n",
    "Trains the base regressor on the provided data using time series cross-validation and stores the results.\n",
    "\n",
    "#### predict(self, X)\n",
    "Predicts the target variable for the provided features using the base regressor trained on the full data.\n",
    "\n",
    "### Example\n",
    "```python\n",
    "from ds_utils.ml import RegressorTimeSeriesCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the RegressorTimeSeriesCV with a base regressor and cross-validation strategy\n",
    "reg_tscv = RegressorTimeSeriesCV(base_reg=RandomForestRegressor(), cv=5, verbose=True)\n",
    "\n",
    "# Fit the RegressorTimeSeriesCV to the training data\n",
    "reg_tscv.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for new data\n",
    "predictions = reg_tscv.predict(X_new)\n",
    "\n",
    "# Get the summary of recorded metrics\n",
    "metrics = reg_tscv.metrics_\n",
    "```\n",
    "\n",
    "## `ml.KNNRegressor` Class\n",
    "\n",
    "### Overview\n",
    "The `KNNRegressor` class in the `ml.py` module of the `ds_utils` library is an extension of the `KNeighborsRegressor` from scikit-learn, with modifications to the `predict` method to allow different calculations for predictions and to optionally return the indices of the nearest neighbors.\n",
    "\n",
    "### Initialization\n",
    "The initialization parameters are the same as those of the `KNeighborsRegressor` from scikit-learn. Refer to the [official documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html) for details on the parameters.\n",
    "\n",
    "### Methods\n",
    "\n",
    "#### predict(self, X, return_match_index=False, pred_calc='mean')\n",
    "Predicts the target variable for the provided features and allows different calculations for predictions.\n",
    "\n",
    "##### Parameters\n",
    "- `X` : array-like of shape (n_samples, n_features). Test samples.\n",
    "- `return_match_index` : bool, default=False. Whether to return the index of the nearest matched neighbor.\n",
    "- `pred_calc` : str, default='mean'. The calculation to use for predictions. Possible values are 'mean' and 'median'.\n",
    "\n",
    "##### Returns\n",
    "- `y_pred` : array of shape (n_samples,) or (n_samples, n_outputs). The predicted target variable.\n",
    "- `nearest_matched_index` : array of shape (n_samples,). The index of the nearest matched neighbor. Returned only if `return_match_index=True`.\n",
    "- `neigh_ind` : array of shape (n_samples, n_neighbors). Indices of the neighbors in the training set. Returned only if `return_match_index=True`.\n",
    "\n",
    "### Example\n",
    "```python\n",
    "from ds_utils.ml import KNNRegressor\n",
    "\n",
    "# Initialize the KNNRegressor with specific parameters\n",
    "knn_reg = KNNRegressor(n_neighbors=3)\n",
    "\n",
    "# Fit the KNNRegressor to the training data\n",
    "knn_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for new data and return the index of the nearest matched neighbor\n",
    "predictions, nearest_matched_index, neigh_ind = knn_reg.predict(X_new, return_match_index=True, pred_calc='median')\n",
    "```\n",
    "\n",
    "## `ml.AutoRegressor` Class\n",
    "\n",
    "### Overview\n",
    "The `AutoRegressor` class is designed for performing automated regression tasks, including preprocessing and model fitting. It supports several regression algorithms and allows for easy comparison of their performance on a given dataset. The class provides various methods for model evaluation, feature importance, and visualization.\n",
    "\n",
    "### Initialization\n",
    "```python\n",
    "ar = AutoRegressor(\n",
    "    num_cols,\n",
    "    cat_cols,\n",
    "    target_col,\n",
    "    data=None,\n",
    "    train=None,\n",
    "    test=None,\n",
    "    random_st=42,\n",
    "    log_target=False,\n",
    "    estimator='catboost',\n",
    "    imputer_strategy='simple',\n",
    "    use_catboost_native_cat_features=False,\n",
    "    ohe_min_freq=0.05,\n",
    "    scale_numeric_data=False,\n",
    "    scale_categoric_data=False,\n",
    "    scale_target=False\n",
    ")\n",
    "```\n",
    "\n",
    "#### Parameters\n",
    "- **num_cols**: list\n",
    "  - List of numerical columns in the dataset.\n",
    "- **cat_cols**: list\n",
    "  - List of categorical columns in the dataset.\n",
    "- **target_col**: str\n",
    "  - Target column name in the dataset.\n",
    "- **data**: pd.DataFrame, optional (default=None)\n",
    "  - Input dataset containing both features and target column.\n",
    "- **train**: pd.DataFrame, optional (default=None)\n",
    "  - Training dataset containing both features and target column. Used if `data` is not provided.\n",
    "- **test**: pd.DataFrame, optional (default=None)\n",
    "  - Testing dataset containing both features and target column. Used if `data` is not provided.\n",
    "- **random_st**: int, optional (default=42)\n",
    "  - Random state for reproducibility.\n",
    "- **log_target**: bool, optional (default=False)\n",
    "  - If the logarithm of the target variable should be used.\n",
    "- **estimator**: str or estimator object, optional (default='catboost')\n",
    "  - String or estimator object. Options are 'catboost', 'random_forest', and 'linear'.\n",
    "- **imputer_strategy**: str, optional (default='simple')\n",
    "  - Imputation strategy for missing values. Options are 'simple' and 'knn'.\n",
    "- **use_catboost_native_cat_features**: bool, optional (default=False)\n",
    "  - If the native CatBoost categorical feature handling should be used.\n",
    "- **ohe_min_freq**: float, optional (default=0.05)\n",
    "  - Minimum frequency for OneHotEncoder to consider a category in categorical columns.\n",
    "- **scale_numeric_data**: bool, optional (default=False)\n",
    "  - If numeric data should be scaled using StandardScaler.\n",
    "- **scale_categoric_data**: bool, optional (default=False)\n",
    "  - If categorical data (after one-hot encoding) should be scaled using StandardScaler.\n",
    "- **scale_target**: bool, optional (default=False)\n",
    "  - If the target variable should be scaled using StandardScaler.\n",
    "\n",
    "### Methods\n",
    "\n",
    "#### fit_report(self)\n",
    "Fits the model to the training data and prints the R2 Score, RMSE, and MAPE on the test data.\n",
    "\n",
    "#### test_binary_column(self, binary_column)\n",
    "Tests the significance of a binary column on the target variable and returns the p-value for Mannâ€“Whitney U test.\n",
    "\n",
    "#### get_coefficients(self)\n",
    "Returns the coefficients of the model if the estimator is linear, otherwise returns feature importances.\n",
    "\n",
    "#### get_feature_importances(self)\n",
    "Returns the feature importances of the model.\n",
    "\n",
    "#### get_shap(self, return_shap_values=False)\n",
    "Generates and plots SHAP values for the model and returns SHAP values if `return_shap_values` is True.\n",
    "\n",
    "#### plot_importance(self, feat_imp, graph_title=\"Model feature importance\")\n",
    "Plots the feature importances provided in `feat_imp` with the specified `graph_title`.\n",
    "\n",
    "### Example Usage\n",
    "```python\n",
    "# Initialize AutoRegressor\n",
    "ar = AutoRegressor(num_cols, cat_cols, target_col, data)\n",
    "\n",
    "# Fit the model and print the report\n",
    "ar.fit_report()\n",
    "\n",
    "# Get and plot feature importances\n",
    "feat_imp = ar.get_feature_importances()\n",
    "ar.plot_importance(feat_imp)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
