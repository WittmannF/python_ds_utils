[
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "ml",
    "section": "",
    "text": "source"
  },
  {
    "objectID": "ml.html#import-regression-dataset-for-testing",
    "href": "ml.html#import-regression-dataset-for-testing",
    "title": "ml",
    "section": "Import Regression Dataset for Testing",
    "text": "Import Regression Dataset for Testing\n\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.compose import make_column_selector\nimport numpy as np\nimport pandas as pd\n\n# Load the Ames Housing dataset\nhousing = fetch_openml(name=\"house_prices\", as_frame=True)\nX = housing['data'].fillna(np.nan)\ny = housing['target']\ndata = pd.concat([X, y], axis=1)\n\nnum_cols = make_column_selector(dtype_include=np.number)(X)\ncat_cols = make_column_selector(dtype_include=object)(X)\n\n# Fill na in X with most frequent for cat_cols and median for num_cols\nX_cat = X[cat_cols].fillna(X[cat_cols].mode().iloc[0])\nX_num = X[num_cols].fillna(X[num_cols].median())\n\nThe default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n\n\n\ny.shape\n\n(1460,)\n\n\n\ndata.head()\n\n\n\n\n\n\n\n\nId\nMSSubClass\nMSZoning\nLotFrontage\nLotArea\nStreet\nAlley\nLotShape\nLandContour\nUtilities\n...\nPoolArea\nPoolQC\nFence\nMiscFeature\nMiscVal\nMoSold\nYrSold\nSaleType\nSaleCondition\nSalePrice\n\n\n\n\n0\n1\n60\nRL\n65.0\n8450\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2008\nWD\nNormal\n208500\n\n\n1\n2\n20\nRL\n80.0\n9600\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n5\n2007\nWD\nNormal\n181500\n\n\n2\n3\n60\nRL\n68.0\n11250\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n9\n2008\nWD\nNormal\n223500\n\n\n3\n4\n70\nRL\n60.0\n9550\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2006\nWD\nAbnorml\n140000\n\n\n4\n5\n60\nRL\n84.0\n14260\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n12\n2008\nWD\nNormal\n250000\n\n\n\n\n5 rows × 81 columns\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1460 entries, 0 to 1459\nData columns (total 81 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   Id             1460 non-null   int64  \n 1   MSSubClass     1460 non-null   int64  \n 2   MSZoning       1460 non-null   object \n 3   LotFrontage    1201 non-null   float64\n 4   LotArea        1460 non-null   int64  \n 5   Street         1460 non-null   object \n 6   Alley          91 non-null     object \n 7   LotShape       1460 non-null   object \n 8   LandContour    1460 non-null   object \n 9   Utilities      1460 non-null   object \n 10  LotConfig      1460 non-null   object \n 11  LandSlope      1460 non-null   object \n 12  Neighborhood   1460 non-null   object \n 13  Condition1     1460 non-null   object \n 14  Condition2     1460 non-null   object \n 15  BldgType       1460 non-null   object \n 16  HouseStyle     1460 non-null   object \n 17  OverallQual    1460 non-null   int64  \n 18  OverallCond    1460 non-null   int64  \n 19  YearBuilt      1460 non-null   int64  \n 20  YearRemodAdd   1460 non-null   int64  \n 21  RoofStyle      1460 non-null   object \n 22  RoofMatl       1460 non-null   object \n 23  Exterior1st    1460 non-null   object \n 24  Exterior2nd    1460 non-null   object \n 25  MasVnrType     1452 non-null   object \n 26  MasVnrArea     1452 non-null   float64\n 27  ExterQual      1460 non-null   object \n 28  ExterCond      1460 non-null   object \n 29  Foundation     1460 non-null   object \n 30  BsmtQual       1423 non-null   object \n 31  BsmtCond       1423 non-null   object \n 32  BsmtExposure   1422 non-null   object \n 33  BsmtFinType1   1423 non-null   object \n 34  BsmtFinSF1     1460 non-null   int64  \n 35  BsmtFinType2   1422 non-null   object \n 36  BsmtFinSF2     1460 non-null   int64  \n 37  BsmtUnfSF      1460 non-null   int64  \n 38  TotalBsmtSF    1460 non-null   int64  \n 39  Heating        1460 non-null   object \n 40  HeatingQC      1460 non-null   object \n 41  CentralAir     1460 non-null   object \n 42  Electrical     1459 non-null   object \n 43  1stFlrSF       1460 non-null   int64  \n 44  2ndFlrSF       1460 non-null   int64  \n 45  LowQualFinSF   1460 non-null   int64  \n 46  GrLivArea      1460 non-null   int64  \n 47  BsmtFullBath   1460 non-null   int64  \n 48  BsmtHalfBath   1460 non-null   int64  \n 49  FullBath       1460 non-null   int64  \n 50  HalfBath       1460 non-null   int64  \n 51  BedroomAbvGr   1460 non-null   int64  \n 52  KitchenAbvGr   1460 non-null   int64  \n 53  KitchenQual    1460 non-null   object \n 54  TotRmsAbvGrd   1460 non-null   int64  \n 55  Functional     1460 non-null   object \n 56  Fireplaces     1460 non-null   int64  \n 57  FireplaceQu    770 non-null    object \n 58  GarageType     1379 non-null   object \n 59  GarageYrBlt    1379 non-null   float64\n 60  GarageFinish   1379 non-null   object \n 61  GarageCars     1460 non-null   int64  \n 62  GarageArea     1460 non-null   int64  \n 63  GarageQual     1379 non-null   object \n 64  GarageCond     1379 non-null   object \n 65  PavedDrive     1460 non-null   object \n 66  WoodDeckSF     1460 non-null   int64  \n 67  OpenPorchSF    1460 non-null   int64  \n 68  EnclosedPorch  1460 non-null   int64  \n 69  3SsnPorch      1460 non-null   int64  \n 70  ScreenPorch    1460 non-null   int64  \n 71  PoolArea       1460 non-null   int64  \n 72  PoolQC         7 non-null      object \n 73  Fence          281 non-null    object \n 74  MiscFeature    54 non-null     object \n 75  MiscVal        1460 non-null   int64  \n 76  MoSold         1460 non-null   int64  \n 77  YrSold         1460 non-null   int64  \n 78  SaleType       1460 non-null   object \n 79  SaleCondition  1460 non-null   object \n 80  SalePrice      1460 non-null   int64  \ndtypes: float64(3), int64(35), object(43)\nmemory usage: 924.0+ KB"
  },
  {
    "objectID": "ml.html#autoregressor-1",
    "href": "ml.html#autoregressor-1",
    "title": "ml",
    "section": "AutoRegressor",
    "text": "AutoRegressor\n\nar = AutoRegressor(\n    num_cols=num_cols,\n    cat_cols=cat_cols,\n    target_col='SalePrice',\n    use_catboost_native_cat_features=True,\n    data=data,\n)\nar.fit_report()\n\nImputer strategy: SimpleImputer(strategy='median')\nUsing estimator &lt;catboost.core.CatBoostRegressor object&gt;\nR2 Score: 0.9160567995409361\nRMSE: 24249.702308651435\nMAPE: 0.08528036637019434\n\n\n\nar.get_feature_importances().head(10).sort_values().plot.barh()\n\n&lt;Axes: &gt;\n\n\n\n\n\n\nar.get_shap()"
  },
  {
    "objectID": "ml.html#catboostregressorcv-1",
    "href": "ml.html#catboostregressorcv-1",
    "title": "ml",
    "section": "CatBoostRegressorCV",
    "text": "CatBoostRegressorCV\n\n# Concat X_cat and X_num for using in catboost\nX_catboost = pd.concat([X_cat, X_num], axis=1)\n\n\nX_catboost.head()\n\n\n\n\n\n\n\n\nMSZoning\nStreet\nAlley\nLotShape\nLandContour\nUtilities\nLotConfig\nLandSlope\nNeighborhood\nCondition1\n...\nGarageArea\nWoodDeckSF\nOpenPorchSF\nEnclosedPorch\n3SsnPorch\nScreenPorch\nPoolArea\nMiscVal\nMoSold\nYrSold\n\n\n\n\n0\nRL\nPave\nGrvl\nReg\nLvl\nAllPub\nInside\nGtl\nCollgCr\nNorm\n...\n548\n0\n61\n0\n0\n0\n0\n0\n2\n2008\n\n\n1\nRL\nPave\nGrvl\nReg\nLvl\nAllPub\nFR2\nGtl\nVeenker\nFeedr\n...\n460\n298\n0\n0\n0\n0\n0\n0\n5\n2007\n\n\n2\nRL\nPave\nGrvl\nIR1\nLvl\nAllPub\nInside\nGtl\nCollgCr\nNorm\n...\n608\n0\n42\n0\n0\n0\n0\n0\n9\n2008\n\n\n3\nRL\nPave\nGrvl\nIR1\nLvl\nAllPub\nCorner\nGtl\nCrawfor\nNorm\n...\n642\n0\n35\n272\n0\n0\n0\n0\n2\n2006\n\n\n4\nRL\nPave\nGrvl\nIR1\nLvl\nAllPub\nFR2\nGtl\nNoRidge\nNorm\n...\n836\n192\n84\n0\n0\n0\n0\n0\n12\n2008\n\n\n\n\n5 rows × 80 columns\n\n\n\n\ncbcv = CatBoostRegressorCV(\n    cat_features=list(range(len(cat_cols)))\n)\ncbcv.fit(X_catboost, y)\n\nCatBoostRegressorCV(cat_features=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n                                  14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n                                  25, 26, 27, 28, 29, ...])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.CatBoostRegressorCVCatBoostRegressorCV(cat_features=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n                                  14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n                                  25, 26, 27, 28, 29, ...])\n\n\n\ncbcv.score(X_catboost, y)\n\n0.9835889355851075\n\n\n\ncbcv.metrics_\n\n\n\n\n\n\n\n\nr2_score\nrmse\nmape\n\n\n\n\n0\n0.907499\n26636.677034\n0.093462\n\n\n1\n0.934493\n21104.525601\n0.080070\n\n\n2\n0.708497\n40130.504754\n0.098265\n\n\n3\n0.886393\n26708.645472\n0.093434\n\n\n4\n0.925741\n19701.295826\n0.075160\n\n\nmean\n0.872524\n26856.329737\n0.088078\n\n\nstd\n0.093532\n8070.804505\n0.009906\n\n\n\n\n\n\n\n\n# Predict the target variable for new data\npredictions = cbcv.predict(X_catboost)\n\n\n# Test CatBoostRegressorCV using AutoRegressor to fill automatically missing values and arrange values automatically\ncbcv = CatBoostRegressorCV(\n    cat_features=list(range(len(cat_cols)))\n)\n\nar = AutoRegressor(\n    num_cols=num_cols,\n    cat_cols=cat_cols,\n    target_col='SalePrice',\n    use_catboost_native_cat_features=True,\n    data=data,\n    estimator=cbcv,\n)\n\nar.fit_report()\n\nImputer strategy: SimpleImputer(strategy='median')\nUsing estimator CatBoostRegressorCV(cat_features=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n                                  14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n                                  25, 26, 27, 28, 29, ...])\nR2 Score: 0.9125046051539697\nRMSE: 24757.469207350325\nMAPE: 0.08813980327749088"
  },
  {
    "objectID": "ml.html#regressortimeseriescv-1",
    "href": "ml.html#regressortimeseriescv-1",
    "title": "ml",
    "section": "RegressorTimeSeriesCV",
    "text": "RegressorTimeSeriesCV\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Initialize the RegressorTimeSeriesCV with a base regressor and cross-validation strategy\nreg_tscv = RegressorTimeSeriesCV(base_reg=RandomForestRegressor(), cv=5)\n\n# Fit the RegressorTimeSeriesCV to the training data\nreg_tscv.fit(X_num, y)\nreg_tscv\n\nRegressorTimeSeriesCV(base_reg=RandomForestRegressor())In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RegressorTimeSeriesCVRegressorTimeSeriesCV(base_reg=RandomForestRegressor())base_reg: RandomForestRegressorRandomForestRegressor()RandomForestRegressorRandomForestRegressor()\n\n\n\nreg_tscv.metrics_\n\n\n\n\n\n\n\n\ntrain_size\ntest_size\ntrain_start_index\ntrain_end_index\ntest_start_index\ntest_end_index\nr2_score\nrmse\nmape\n\n\n\n\n0\n245\n243\n0\n244\n245\n487\n0.870264\n28630.258580\n0.117311\n\n\n1\n488\n243\n0\n487\n488\n730\n0.794495\n40330.053395\n0.132850\n\n\n2\n731\n243\n0\n730\n731\n973\n0.862934\n27865.628836\n0.102215\n\n\n3\n974\n243\n0\n973\n974\n1216\n0.835772\n33497.124956\n0.109466\n\n\n4\n1217\n243\n0\n1216\n1217\n1459\n0.800384\n32331.165167\n0.112466\n\n\nmean\n731\n243\n0\n730\n731\n973\n0.832770\n32530.846187\n0.114862\n\n\nstd\n384\n0\n0\n384\n384\n384\n0.034780\n4969.407330\n0.011450"
  },
  {
    "objectID": "ml.html#knnregressor-1",
    "href": "ml.html#knnregressor-1",
    "title": "ml",
    "section": "KNNRegressor",
    "text": "KNNRegressor\n\n# Initialize the KNNRegressor with specific parameters\nknn_reg = KNNRegressor(n_neighbors=3)\n\n# Fit the KNNRegressor to the training data\nknn_reg.fit(X_num.values, y)\n\n# Predict the target variable for new data and return the index of the nearest matched neighbor\npredictions, nearest_matched_index, neigh_ind = knn_reg.predict(X_num, return_match_index=True, pred_calc='median')\n\n\nknn_reg.score(X_num, y)\n\n0.8264707348813984\n\n\n\npredictions\n\narray([208500., 173000., 223500., ..., 256000., 142125., 147500.])\n\n\n\nnearest_matched_index\n\narray([[   0],\n       [   1],\n       [   2],\n       ...,\n       [1457],\n       [1458],\n       [1459]])\n\n\n\nneigh_ind\n\narray([[   0,  212,  256],\n       [   1,  395,  186],\n       [   2,  280,  222],\n       ...,\n       [1457, 1171, 1328],\n       [1458, 1418, 1259],\n       [1459, 1424, 1259]])"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ds_utils",
    "section": "",
    "text": "pip install ds_utils"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "ds_utils",
    "section": "",
    "text": "pip install ds_utils"
  },
  {
    "objectID": "index.html#development-notes",
    "href": "index.html#development-notes",
    "title": "ds_utils",
    "section": "Development notes",
    "text": "Development notes\nThis library has been developed using nbdev. Any change or PR has to be made directly to the notebooks that creates each module. All tests must pass."
  },
  {
    "objectID": "index.html#ml.regressorcv-class",
    "href": "index.html#ml.regressorcv-class",
    "title": "ds_utils",
    "section": "ml.RegressorCV Class",
    "text": "ml.RegressorCV Class\n\nOverview\nThe RegressorCV class in the ml.py module of the ds_utils library is designed to train an estimator using cross-validation and record metrics for each fold. It also stores each model that is trained on each fold of the cross-validation process. The final prediction is made as the median value of the predictions from each stored model.\n\n\nInitialization\nRegressorCV(base_reg, cv=5, groups=None, verbose=False, n_bins_stratify=None)\n\nParameters\n\nbase_reg : Estimator object implementing ‘fit’. The object to use to fit the data.\ncv : int or cross-validation generator, default=5. Determines the cross-validation splitting strategy.\ngroups : array-like of shape (n_samples,), default=None. Group labels for the samples used while splitting the dataset into train/test set.\nn_bins_stratify : int, default=None. Number of bins to use for stratification.\nverbose : bool, default=False. Whether or not to print metrics.\n\n\n\n\nAttributes\n\ncv_results_ : Dictionary containing the results of the cross-validation, including the fold number, the regressor, and the metrics.\noof_train_ : Series containing the out-of-fold predictions on the training set.\noof_score_ : The R2 score calculated using the out-of-fold predictions.\noof_mape_ : The Mean Absolute Percentage Error calculated using the out-of-fold predictions.\noof_rmse_ : The Root Mean Squared Error calculated using the out-of-fold predictions.\nmetrics_ : The summary of metrics calculated during the fitting process.\n\n\n\nMethods\n\nfit(self, X, y, **kwargs)\nTrains the base regressor on the provided data using cross-validation and stores the results.\n\n\npredict(self, X)\nPredicts the target variable for the provided features using the median value of the predictions from the models trained during cross-validation.\n\n\n\nExample\nfrom ds_utils.ml import RegressorCV\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Initialize the RegressorCV with a base regressor and cross-validation strategy\nreg_cv = RegressorCV(base_reg=RandomForestRegressor(), cv=5, verbose=True)\n\n# Fit the RegressorCV to the training data\nreg_cv.fit(X_train, y_train)\n\n# Predict the target variable for new data\npredictions = reg_cv.predict(X_new)\n\n# Get the summary of recorded metrics\nmetrics = reg_cv.metrics_"
  },
  {
    "objectID": "index.html#ml.regressortimeseriescv-class",
    "href": "index.html#ml.regressortimeseriescv-class",
    "title": "ds_utils",
    "section": "ml.RegressorTimeSeriesCV Class",
    "text": "ml.RegressorTimeSeriesCV Class\n\nOverview\nThe RegressorTimeSeriesCV class in the ml.py module of the ds_utils library is designed to train a base regressor using time series cross-validation and record metrics for each fold.\n\n\nInitialization\nRegressorTimeSeriesCV(base_reg, cv=5, verbose=False, catboost_use_eval_set=False)\n\nParameters\n\nbase_reg : Estimator object implementing ‘fit’. The object to use to fit the data.\ncv : int, default=5. Determines the cross-validation splitting strategy.\nverbose : bool, default=False. Whether or not to print metrics.\ncatboost_use_eval_set : bool, default=False. Whether or not to use eval_set in CatBoostRegressor.\n\n\n\n\nAttributes\n\ncv_results_ : List containing the results of the cross-validation, including fold number, regressor, train and test indices, and metrics.\nmetrics_ : The summary of metrics calculated during the fitting process.\ny_test_last_fold_ : The true target variable values of the last fold.\ny_pred_last_fold_ : The predicted target variable values of the last fold.\n\n\n\nMethods\n\nfit(self, X, y, sample_weight=None)\nTrains the base regressor on the provided data using time series cross-validation and stores the results.\n\n\npredict(self, X)\nPredicts the target variable for the provided features using the base regressor trained on the full data.\n\n\n\nExample\nfrom ds_utils.ml import RegressorTimeSeriesCV\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Initialize the RegressorTimeSeriesCV with a base regressor and cross-validation strategy\nreg_tscv = RegressorTimeSeriesCV(base_reg=RandomForestRegressor(), cv=5, verbose=True)\n\n# Fit the RegressorTimeSeriesCV to the training data\nreg_tscv.fit(X_train, y_train)\n\n# Predict the target variable for new data\npredictions = reg_tscv.predict(X_new)\n\n# Get the summary of recorded metrics\nmetrics = reg_tscv.metrics_"
  },
  {
    "objectID": "index.html#ml.knnregressor-class",
    "href": "index.html#ml.knnregressor-class",
    "title": "ds_utils",
    "section": "ml.KNNRegressor Class",
    "text": "ml.KNNRegressor Class\n\nOverview\nThe KNNRegressor class in the ml.py module of the ds_utils library is an extension of the KNeighborsRegressor from scikit-learn, with modifications to the predict method to allow different calculations for predictions and to optionally return the indices of the nearest neighbors.\n\n\nInitialization\nThe initialization parameters are the same as those of the KNeighborsRegressor from scikit-learn. Refer to the official documentation for details on the parameters.\n\n\nMethods\n\npredict(self, X, return_match_index=False, pred_calc=‘mean’)\nPredicts the target variable for the provided features and allows different calculations for predictions.\n\nParameters\n\nX : array-like of shape (n_samples, n_features). Test samples.\nreturn_match_index : bool, default=False. Whether to return the index of the nearest matched neighbor.\npred_calc : str, default=‘mean’. The calculation to use for predictions. Possible values are ‘mean’ and ‘median’.\n\n\n\nReturns\n\ny_pred : array of shape (n_samples,) or (n_samples, n_outputs). The predicted target variable.\nnearest_matched_index : array of shape (n_samples,). The index of the nearest matched neighbor. Returned only if return_match_index=True.\nneigh_ind : array of shape (n_samples, n_neighbors). Indices of the neighbors in the training set. Returned only if return_match_index=True.\n\n\n\n\n\nExample\nfrom ds_utils.ml import KNNRegressor\n\n# Initialize the KNNRegressor with specific parameters\nknn_reg = KNNRegressor(n_neighbors=3)\n\n# Fit the KNNRegressor to the training data\nknn_reg.fit(X_train, y_train)\n\n# Predict the target variable for new data and return the index of the nearest matched neighbor\npredictions, nearest_matched_index, neigh_ind = knn_reg.predict(X_new, return_match_index=True, pred_calc='median')"
  },
  {
    "objectID": "index.html#ml.autoregressor-class",
    "href": "index.html#ml.autoregressor-class",
    "title": "ds_utils",
    "section": "ml.AutoRegressor Class",
    "text": "ml.AutoRegressor Class\n\nOverview\nThe AutoRegressor class is designed for performing automated regression tasks, including preprocessing and model fitting. It supports several regression algorithms and allows for easy comparison of their performance on a given dataset. The class provides various methods for model evaluation, feature importance, and visualization.\n\n\nInitialization\nar = AutoRegressor(\n    num_cols,\n    cat_cols,\n    target_col,\n    data=None,\n    train=None,\n    test=None,\n    random_st=42,\n    log_target=False,\n    estimator='catboost',\n    imputer_strategy='simple',\n    use_catboost_native_cat_features=False,\n    ohe_min_freq=0.05,\n    scale_numeric_data=False,\n    scale_categoric_data=False,\n    scale_target=False\n)\n\nParameters\n\nnum_cols: list\n\nList of numerical columns in the dataset.\n\ncat_cols: list\n\nList of categorical columns in the dataset.\n\ntarget_col: str\n\nTarget column name in the dataset.\n\ndata: pd.DataFrame, optional (default=None)\n\nInput dataset containing both features and target column.\n\ntrain: pd.DataFrame, optional (default=None)\n\nTraining dataset containing both features and target column. Used if data is not provided.\n\ntest: pd.DataFrame, optional (default=None)\n\nTesting dataset containing both features and target column. Used if data is not provided.\n\nrandom_st: int, optional (default=42)\n\nRandom state for reproducibility.\n\nlog_target: bool, optional (default=False)\n\nIf the logarithm of the target variable should be used.\n\nestimator: str or estimator object, optional (default=‘catboost’)\n\nString or estimator object. Options are ‘catboost’, ‘random_forest’, and ‘linear’.\n\nimputer_strategy: str, optional (default=‘simple’)\n\nImputation strategy for missing values. Options are ‘simple’ and ‘knn’.\n\nuse_catboost_native_cat_features: bool, optional (default=False)\n\nIf the native CatBoost categorical feature handling should be used.\n\nohe_min_freq: float, optional (default=0.05)\n\nMinimum frequency for OneHotEncoder to consider a category in categorical columns.\n\nscale_numeric_data: bool, optional (default=False)\n\nIf numeric data should be scaled using StandardScaler.\n\nscale_categoric_data: bool, optional (default=False)\n\nIf categorical data (after one-hot encoding) should be scaled using StandardScaler.\n\nscale_target: bool, optional (default=False)\n\nIf the target variable should be scaled using StandardScaler.\n\n\n\n\n\nMethods\n\nfit_report(self)\nFits the model to the training data and prints the R2 Score, RMSE, and MAPE on the test data.\n\n\ntest_binary_column(self, binary_column)\nTests the significance of a binary column on the target variable and returns the p-value for Mann–Whitney U test.\n\n\nget_coefficients(self)\nReturns the coefficients of the model if the estimator is linear, otherwise returns feature importances.\n\n\nget_feature_importances(self)\nReturns the feature importances of the model.\n\n\nget_shap(self, return_shap_values=False)\nGenerates and plots SHAP values for the model and returns SHAP values if return_shap_values is True.\n\n\nplot_importance(self, feat_imp, graph_title=“Model feature importance”)\nPlots the feature importances provided in feat_imp with the specified graph_title.\n\n\n\nExample Usage\n# Initialize AutoRegressor\nar = AutoRegressor(num_cols, cat_cols, target_col, data)\n\n# Fit the model and print the report\nar.fit_report()\n\n# Get and plot feature importances\nfeat_imp = ar.get_feature_importances()\nar.plot_importance(feat_imp)"
  }
]